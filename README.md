# 知予AI：从人工智能学习者到人工智能研究者 🪐

摘要：越来越多的学生已加入到**人工智能**（Artificial Intelligence, AI）的学习和研究中，并且将AI应用到自己的生活和工作中。然而在研究和学习过程中，大家往往会遇到数不清的坎坷和挫折，可能是对某个算法的概念难以理解，可能是编程中某个bug难以解决，也可能是无法想出研究idea时感到迷茫。**知予AI**（Knove-AI）立志于解决这一问题。首先，知予AI是一份内容丰富的**中英文学习手册**：手册涵盖了人工智能领域的多个方向的**基础知识、算法原理、代码实现**等，并引导从“人工智能的学习者”到“人工智能的研究者”进行过渡，真正参与到人工智能的前沿研究，包括**确定研究方向，进行实验，撰写人工智能领域的论文**等。其次，知予AI是一个**链接富有经验的人工智能的学者和和初出茅庐的人工智能新手的桥梁**：知予AI学习手册由来自清华大学、北京大学、 中国人民大学、哥伦比亚大学等高校的多名优秀的博士研究生及研究员整理。这些学者作为过来人深知学习和研究过程中的不易，因此知予AI提供了**学习者与教学者一对一交流**的机会。

## 知予AI立志于构建一个涵盖学习者、学习资源、以及教学者的三位一体的人工智能学习平台 ⚡

### (1) 学习者（Learner）🧑‍🎓

你可以是完全不懂人工智能的小白，也可以是刚刚打算或者正在学习人工智能的大学生，亦或是打算从事人工智能研究的研究生。你也可能正在准备做一些大学生**科研立项**，参加一些**科技竞赛**，发表人工智能领域的**论文**，准备**考研、保研、申博、留学**等。只要你对人工智能等学习和研究充满了热情和渴望，知予AI都能够为你提供有力的帮助。

### (2) 学习资源（Resource）📑

网上的学习资源可以说是五花八门，鱼龙混杂。为了尽量减少大家在学习过程中寻找资源耗费的时间和人力成本，我们直接整合了全网具有较高学习价值的**书籍、课程、网站、博客、论文**等，并对诸多主流的学习资源给出了中肯的评价。

### (3) 教学者（Teacher）🧑‍🏫

在人工智能学习和研究的过程中，有很多问题是通过自己查找资料无法解决的，但是有时一个富有经验的前辈往往能够提供巨大的帮助。知予AI在提供学习资源的基础上，引入了教学者这一角色，这些教学者都是曾在顶级会议/期刊发表过多篇论文的富有经验的人工智能不同领域的学者/研究人员。平台提供学习者与教学者**一对一线上交流**的机会，从而个性化地解决学习者在学习和研究过程中遇到的各类问题。

## 学习者在这个平台能得到什么 🤔

(1) **人工智能基础知识的学习** 💡：多名优秀的博士生将人工智能**数理基础、机器学习、深度学习、自然语言处理、计算机视觉**等方向的主流学习资源汇总为统一格式的学习手册。该手册同时兼顾广度和深度，可以作为全面学习人工智能基础的资源。每个章节都涵盖了相关知识点、算法详解、代码实现、练手项目、以及所参考的学习资料出处。手册采用Markdown格式进行整理，简明扼要，图文并茂，格式美观统一，学习体验良好。

(2) **从“学习者”变成“研究者**”🧐：知予AI将逐步发布AI研究手册系列，包括介绍**从学习思维到研究思维的转化、AI研究方向的选择、AI交叉学科、如何撰写以及发表一篇AI研究论文、如何进行科研实验**等。

(3) **与富有经验的教学者一对一交流** 💬：平台提供与富有经验的优秀博士生/研究人员一对一交流的机会。如果学习者在学习和研究过程中需要进行**学习路径规划、研究路线规划、一对一请教学习**，或者遇到了**升学、留学、就业、竞赛、项目、论文撰写**等方面的难题，都可以与我们的对接客服小姐姐联系（微信号和二维码见“联系我们”），从而进一步链接到能够帮助解决问题的教学者。**我们不同于网上鱼龙混杂的中介平台，在这一过程中，知予AI不会收取任何中介费用，请放心联系**。

## 目录 📖

### 知予AI学习手册

<table>
  <thead>
    <tr>
      <th>章</th>
      <th>节</th>
      <th>内容</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td rowspan="5"><a href="#wrench-installation">人工智能的数学基础</a></td>
      <td><a href="#wrench-installation">线性代数</a></td>
      <td>Bi-encoder models such as dpr, bge, e5, using faiss for search</td>
    </tr>
    <tr>
      <td><a href="#wrench-installation">微积分</a></td>
      <td>Sparse retrieval method based on Lucene</td>
    </tr>
    <tr>
      <td><a href="#wrench-installation">数学优化</a></td>
      <td>Calculate matching score using bi-Encoder</td>
    </tr>
    <tr>
      <td><a href="#wrench-installation">概率统计</a></td>
      <td>Calculate matching score using cross-encoder</td>
    </tr>
    <tr>
      <td><a href="#wrench-installation">信息论</a></td>
      <td>Calculate matching score using cross-encoder</td>
    </tr>
    <tr>
      <td rowspan="20">机器学习</td>
      <td>机器学习概述</td>
      <td>Refine input by extracting important context</td>
    </tr>
    <tr>
      <td>线性回归</td>
      <td>Refine input through seq2seq model</td>
    </tr>
    <tr>
      <td>k近邻算法</td>
      <td><a href="https://aclanthology.org/2023.emnlp-main.825/">LLMLingua-series</a> prompt compressor</td>
    </tr>
    <tr>
      <td>感知机</td>
      <td><a href="https://arxiv.org/abs/2310.06201">Selective-Context</a> prompt compressor</td>
    </tr>
    <tr>
      <td>贝叶斯分类器</td>
      <td>Use <a hred='https://arxiv.org/abs/2406.11460'>Trace method to construct a knowledge graph</td>
    <tr>
    <tr>
      <td>逻辑回归与最大熵模型</td>
      <td>Use <a hred='https://arxiv.org/abs/2406.11460'>Trace method to construct a knowledge graph</td>
    <tr>
    <tr>
      <td>支持向量机</td>
      <td>Use <a hred='https://arxiv.org/abs/2406.11460'>Trace method to construct a knowledge graph</td>
    <tr>
    <tr>
      <td>决策树与随机森林</td>
      <td>Use <a hred='https://arxiv.org/abs/2406.11460'>Trace method to construct a knowledge graph</td>
    <tr>
    <tr>
      <td>集成学习</td>
      <td>Use <a hred='https://arxiv.org/abs/2406.11460'>Trace method to construct a knowledge graph</td>
    <tr>
    <tr>
      <td>EM算法</td>
      <td>Use <a hred='https://arxiv.org/abs/2406.11460'>Trace method to construct a knowledge graph</td>
    <tr>
    <tr>
      <td>聚类</td>
      <td>Use <a hred='https://arxiv.org/abs/2406.11460'>Trace method to construct a knowledge graph</td>
    <tr>
    <tr>
      <td>降维</td>
      <td>Use <a hred='https://arxiv.org/abs/2406.11460'>Trace method to construct a knowledge graph</td>
    <tr>
    <tr>
      <td>特征选择</td>
      <td>Use <a hred='https://arxiv.org/abs/2406.11460'>Trace method to construct a knowledge graph</td>
    <tr>
    <tr>
      <td>话题模型</td>
      <td>Use <a hred='https://arxiv.org/abs/2406.11460'>Trace method to construct a knowledge graph</td>
    <tr>
    <tr>
      <td>概率图模型</td>
      <td>Use <a hred='https://arxiv.org/abs/2406.11460'>Trace method to construct a knowledge graph</td>
    <tr>
      <td rowspan="10">深度学习</td>
      <td>深度学习概述</td>
      <td>Encoder-Decoder model, supporting <a href="https://arxiv.org/abs/2007.01282">Fusion-in-Decoder (FiD)</a></td>
    </tr>
    <tr>
      <td>神经网络模型</td>
      <td>Accelerate with <a href="https://github.com/lm-sys/FastChat">FastChat</a></td>
    </tr>
    <tr>
      <td>卷积神经网络</td>
      <td>Accelerate with <a href="https://github.com/vllm-project/vllm">vllm</a></td>
    </tr>
    <tr>
      <td>循环神经网络</td>
      <td>Accelerate with <a href="https://github.com/vllm-project/vllm">vllm</a></td>
    </tr>
    <tr>
      <td>神经网络的优化</td>
      <td>Accelerate with <a href="https://github.com/vllm-project/vllm">vllm</a></td>
    </tr>
    <tr>
      <td>自编码器</td>
      <td>Accelerate with <a href="https://github.com/vllm-project/vllm">vllm</a></td>
    </tr>
    <tr>
      <td>深度生成模型</td>
      <td>Accelerate with <a href="https://github.com/vllm-project/vllm">vllm</a></td>
    </tr>
    <tr>
      <td>注意力机制与外部记忆</td>
      <td>Accelerate with <a href="https://github.com/vllm-project/vllm">vllm</a></td>
    </tr>
    <tr>
      <td>图神经网络</td>
      <td>Accelerate with <a href="https://github.com/vllm-project/vllm">vllm</a></td>
    </tr>
    <tr>
      <td>深度强化学习</td>
      <td>Accelerate with <a href="https://github.com/vllm-project/vllm">vllm</a></td>
    </tr>
    <tr>
      <td rowspan="10">自然语言处理</td>
      <td>自然语言处理概述</td>
      <td>Encoder-Decoder model, supporting <a href="https://arxiv.org/abs/2007.01282">Fusion-in-Decoder (FiD)</a></td>
    </tr>
    <tr>
      <td>词向量</td>
      <td>Accelerate with <a href="https://github.com/lm-sys/FastChat">FastChat</a></td>
    </tr>
    <tr>
      <td>语言模型</td>
      <td>Accelerate with <a href="https://github.com/vllm-project/vllm">vllm</a></td>
    </tr>
    <tr>
      <td>序列到序列</td>
      <td>Accelerate with <a href="https://github.com/vllm-project/vllm">vllm</a></td>
    </tr>
    <tr>
      <td>预训练模型</td>
      <td>Accelerate with <a href="https://github.com/vllm-project/vllm">vllm</a></td>
    </tr>
    <tr>
      <td>大语言模型</td>
      <td>Accelerate with <a href="https://github.com/vllm-project/vllm">vllm</a></td>
    </tr>
    <tr>
      <td>自然语言处理应用</td>
      <td>Accelerate with <a href="https://github.com/vllm-project/vllm">vllm</a></td>
    </tr>
  </tbody>
</table>

### 知予AI研究手册

敬请期待～

## 联系我们 ☎️

**如需要与教学者进行一对一交流，请添加对接小姐姐微信号PhiNorm，或扫描以下二维码：**

<img src="assets/QRcode.jpeg" style="width: 30%;">

## News 📰

[2024-09-29] 知予AI平台中文研究手册发布准备中！💪

[2024-09-29] 知予AI平台中文学习手册在Github正式发布！🎉
